{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1844f2ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6dcba928",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Logging configured\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "import os\n",
    "\n",
    "# Clean up any previous logs\n",
    "for log_file in [\"logger.log\", \"web.log\", \"tunnel.log\"]:\n",
    "    if os.path.exists(log_file):\n",
    "        os.remove(log_file)\n",
    "        print(f\"ðŸ§¹ Cleaned up {log_file}\")\n",
    "\n",
    "# Configure logging with DEBUG log level.\n",
    "logging.basicConfig(\n",
    "    filename=\"logger.log\",\n",
    "    level=logging.DEBUG,\n",
    "    format=\"%(filename)s:%(lineno)s %(levelname)s:%(message)s\",\n",
    ")\n",
    "\n",
    "print(\"âœ… Logging configured\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1dd5337b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/kshitizraj/miniconda3/envs/gemini-adk/lib/python3.13/site-packages/google/cloud/aiplatform/models.py:52: FutureWarning: Support for google-cloud-storage < 3.0.0 will be removed in a future version of google-cloud-aiplatform. Please upgrade to google-cloud-storage >= 3.0.0.\n",
      "  from google.cloud.aiplatform.utils import gcs_utils\n",
      "Error: Option '--api_key' requires an argument.\n"
     ]
    }
   ],
   "source": [
    "!adk create research-agent --model gemini-2.5-flash-lite --api_key $GOOGLE_API_KEY\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "daacac21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Agent created\n"
     ]
    }
   ],
   "source": [
    "from google.adk.agents import LlmAgent\n",
    "from google.adk.models.google_llm import Gemini\n",
    "from google.adk.tools.agent_tool import AgentTool\n",
    "from google.adk.tools.google_search_tool import google_search\n",
    "\n",
    "from google.genai import types\n",
    "from typing import List\n",
    "\n",
    "retry_config = types.HttpRetryOptions(\n",
    "    attempts=5,  # Maximum retry attempts\n",
    "    exp_base=7,  # Delay multiplier\n",
    "    initial_delay=1,\n",
    "    http_status_codes=[429, 500, 503, 504],  # Retry on these HTTP errors\n",
    ")\n",
    "\n",
    "\n",
    "def count_papers(papers: List[str]):\n",
    "    \"\"\"\n",
    "    This function counts the number of papers in a list of strings.\n",
    "    Args:\n",
    "      papers: A list of strings, where each string is a research paper.\n",
    "    Returns:\n",
    "      The number of papers in the list.\n",
    "    \"\"\"\n",
    "    return len(papers)\n",
    "\n",
    "\n",
    "# Google search agent\n",
    "google_search_agent = LlmAgent(\n",
    "    name=\"google_search_agent\",\n",
    "    model=Gemini(model=\"gemini-2.5-flash-lite\", retry_options=retry_config),\n",
    "    description=\"Searches for information using Google search\",\n",
    "    instruction=\"Use the google_search tool to find information on the given topic. Return the raw search results.\",\n",
    "    tools=[google_search],\n",
    ")\n",
    "\n",
    "# Root agent\n",
    "research_agent_with_plugin = LlmAgent(\n",
    "    name=\"research_paper_finder_agent\",\n",
    "    model=Gemini(model=\"gemini-2.5-flash-lite\", retry_options=retry_config),\n",
    "    instruction=\"\"\"Your task is to find research papers and count them. \n",
    "   \n",
    "   You must follow these steps:\n",
    "   1) Find research papers on the user provided topic using the 'google_search_agent'. \n",
    "   2) Then, pass the papers to 'count_papers' tool to count the number of papers returned.\n",
    "   3) Return both the list of research papers and the total number of papers.\n",
    "   \"\"\",\n",
    "    tools=[AgentTool(agent=google_search_agent), count_papers],\n",
    ")\n",
    "\n",
    "print(\"âœ… Agent created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "602a4700",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Runner configured\n"
     ]
    }
   ],
   "source": [
    "from google.adk.runners import InMemoryRunner\n",
    "from google.adk.plugins.logging_plugin import (\n",
    "    LoggingPlugin,\n",
    ")  # <---- 1. Import the Plugin\n",
    "from google.genai import types\n",
    "import asyncio\n",
    "\n",
    "runner = InMemoryRunner(\n",
    "    agent=research_agent_with_plugin,\n",
    "    plugins=[\n",
    "        LoggingPlugin()\n",
    "    ],  # <---- 2. Add the plugin. Handles standard Observability logging across ALL agents\n",
    ")\n",
    "\n",
    "print(\"âœ… Runner configured\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ac9c5f01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸš€ Running agent with LoggingPlugin...\n",
      "ðŸ“Š Watch the comprehensive logging output below:\n",
      "\n",
      "\n",
      " ### Created new session: debug_session_id\n",
      "\n",
      "User > Find recent papers on quantum computing\n",
      "\u001b[90m[logging_plugin] ðŸš€ USER MESSAGE RECEIVED\u001b[0m\n",
      "\u001b[90m[logging_plugin]    Invocation ID: e-c592114d-0e5b-41dc-943a-10a0cc349644\u001b[0m\n",
      "\u001b[90m[logging_plugin]    Session ID: debug_session_id\u001b[0m\n",
      "\u001b[90m[logging_plugin]    User ID: debug_user_id\u001b[0m\n",
      "\u001b[90m[logging_plugin]    App Name: InMemoryRunner\u001b[0m\n",
      "\u001b[90m[logging_plugin]    Root Agent: research_paper_finder_agent\u001b[0m\n",
      "\u001b[90m[logging_plugin]    User Content: text: 'Find recent papers on quantum computing'\u001b[0m\n",
      "\u001b[90m[logging_plugin] ðŸƒ INVOCATION STARTING\u001b[0m\n",
      "\u001b[90m[logging_plugin]    Invocation ID: e-c592114d-0e5b-41dc-943a-10a0cc349644\u001b[0m\n",
      "\u001b[90m[logging_plugin]    Starting Agent: research_paper_finder_agent\u001b[0m\n",
      "\u001b[90m[logging_plugin] ðŸ¤– AGENT STARTING\u001b[0m\n",
      "\u001b[90m[logging_plugin]    Agent Name: research_paper_finder_agent\u001b[0m\n",
      "\u001b[90m[logging_plugin]    Invocation ID: e-c592114d-0e5b-41dc-943a-10a0cc349644\u001b[0m\n",
      "\u001b[90m[logging_plugin] ðŸ§  LLM REQUEST\u001b[0m\n",
      "\u001b[90m[logging_plugin]    Model: gemini-2.5-flash-lite\u001b[0m\n",
      "\u001b[90m[logging_plugin]    Agent: research_paper_finder_agent\u001b[0m\n",
      "\u001b[90m[logging_plugin]    System Instruction: 'Your task is to find research papers and count them. \n",
      "\n",
      "   You must follow these steps:\n",
      "   1) Find research papers on the user provided topic using the 'google_search_agent'. \n",
      "   2) Then, pass the pape...'\u001b[0m\n",
      "\u001b[90m[logging_plugin]    Available Tools: ['google_search_agent', 'count_papers']\u001b[0m\n",
      "\u001b[90m[logging_plugin] ðŸ§  LLM ERROR\u001b[0m\n",
      "\u001b[90m[logging_plugin]    Agent: research_paper_finder_agent\u001b[0m\n",
      "\u001b[90m[logging_plugin]    Error: Missing key inputs argument! To use the Google AI API, provide (`api_key`) arguments. To use the Google Cloud API, provide (`vertexai`, `project` & `location`) arguments.\u001b[0m\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Missing key inputs argument! To use the Google AI API, provide (`api_key`) arguments. To use the Google Cloud API, provide (`vertexai`, `project` & `location`) arguments.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mðŸš€ Running agent with LoggingPlugin...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      2\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mðŸ“Š Watch the comprehensive logging output below:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m response = \u001b[38;5;28;01mawait\u001b[39;00m runner.run_debug(\u001b[33m\"\u001b[39m\u001b[33mFind recent papers on quantum computing\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Development/Google-ai/aiEnv/lib/python3.13/site-packages/google/adk/runners.py:1023\u001b[39m, in \u001b[36mRunner.run_debug\u001b[39m\u001b[34m(self, user_messages, user_id, session_id, run_config, quiet, verbose)\u001b[39m\n\u001b[32m   1020\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m quiet:\n\u001b[32m   1021\u001b[39m   \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mUser > \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmessage\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1023\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m event \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.run_async(\n\u001b[32m   1024\u001b[39m     user_id=user_id,\n\u001b[32m   1025\u001b[39m     session_id=session.id,\n\u001b[32m   1026\u001b[39m     new_message=types.UserContent(parts=[types.Part(text=message)]),\n\u001b[32m   1027\u001b[39m     run_config=run_config,\n\u001b[32m   1028\u001b[39m ):\n\u001b[32m   1029\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m quiet:\n\u001b[32m   1030\u001b[39m     print_event(event, verbose=verbose)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Development/Google-ai/aiEnv/lib/python3.13/site-packages/google/adk/runners.py:443\u001b[39m, in \u001b[36mRunner.run_async\u001b[39m\u001b[34m(self, user_id, session_id, invocation_id, new_message, state_delta, run_config)\u001b[39m\n\u001b[32m    436\u001b[39m       asyncio.create_task(\n\u001b[32m    437\u001b[39m           _run_compaction_for_sliding_window(\n\u001b[32m    438\u001b[39m               \u001b[38;5;28mself\u001b[39m.app, session, \u001b[38;5;28mself\u001b[39m.session_service\n\u001b[32m    439\u001b[39m           )\n\u001b[32m    440\u001b[39m       )\n\u001b[32m    442\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mwith\u001b[39;00m Aclosing(_run_with_trace(new_message, invocation_id)) \u001b[38;5;28;01mas\u001b[39;00m agen:\n\u001b[32m--> \u001b[39m\u001b[32m443\u001b[39m   \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m event \u001b[38;5;129;01min\u001b[39;00m agen:\n\u001b[32m    444\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m event\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Development/Google-ai/aiEnv/lib/python3.13/site-packages/google/adk/runners.py:427\u001b[39m, in \u001b[36mRunner.run_async.<locals>._run_with_trace\u001b[39m\u001b[34m(new_message, invocation_id)\u001b[39m\n\u001b[32m    417\u001b[39m       \u001b[38;5;28;01myield\u001b[39;00m event\n\u001b[32m    419\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mwith\u001b[39;00m Aclosing(\n\u001b[32m    420\u001b[39m     \u001b[38;5;28mself\u001b[39m._exec_with_plugin(\n\u001b[32m    421\u001b[39m         invocation_context=invocation_context,\n\u001b[32m   (...)\u001b[39m\u001b[32m    425\u001b[39m     )\n\u001b[32m    426\u001b[39m ) \u001b[38;5;28;01mas\u001b[39;00m agen:\n\u001b[32m--> \u001b[39m\u001b[32m427\u001b[39m   \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m event \u001b[38;5;129;01min\u001b[39;00m agen:\n\u001b[32m    428\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m event\n\u001b[32m    429\u001b[39m \u001b[38;5;66;03m# Run compaction after all events are yielded from the agent.\u001b[39;00m\n\u001b[32m    430\u001b[39m \u001b[38;5;66;03m# (We don't compact in the middle of an invocation, we only compact at the end of an invocation.)\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Development/Google-ai/aiEnv/lib/python3.13/site-packages/google/adk/runners.py:653\u001b[39m, in \u001b[36mRunner._exec_with_plugin\u001b[39m\u001b[34m(self, invocation_context, session, execute_fn, is_live_call)\u001b[39m\n\u001b[32m    650\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    651\u001b[39m   \u001b[38;5;66;03m# Step 2: Otherwise continue with normal execution\u001b[39;00m\n\u001b[32m    652\u001b[39m   \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mwith\u001b[39;00m Aclosing(execute_fn(invocation_context)) \u001b[38;5;28;01mas\u001b[39;00m agen:\n\u001b[32m--> \u001b[39m\u001b[32m653\u001b[39m     \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m event \u001b[38;5;129;01min\u001b[39;00m agen:\n\u001b[32m    654\u001b[39m       \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m event.partial:\n\u001b[32m    655\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._should_append_event(event, is_live_call):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Development/Google-ai/aiEnv/lib/python3.13/site-packages/google/adk/runners.py:416\u001b[39m, in \u001b[36mRunner.run_async.<locals>._run_with_trace.<locals>.execute\u001b[39m\u001b[34m(ctx)\u001b[39m\n\u001b[32m    414\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mexecute\u001b[39m(ctx: InvocationContext) -> AsyncGenerator[Event]:\n\u001b[32m    415\u001b[39m   \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mwith\u001b[39;00m Aclosing(ctx.agent.run_async(ctx)) \u001b[38;5;28;01mas\u001b[39;00m agen:\n\u001b[32m--> \u001b[39m\u001b[32m416\u001b[39m     \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m event \u001b[38;5;129;01min\u001b[39;00m agen:\n\u001b[32m    417\u001b[39m       \u001b[38;5;28;01myield\u001b[39;00m event\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Development/Google-ai/aiEnv/lib/python3.13/site-packages/google/adk/agents/base_agent.py:294\u001b[39m, in \u001b[36mBaseAgent.run_async\u001b[39m\u001b[34m(self, parent_context)\u001b[39m\n\u001b[32m    291\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[32m    293\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mwith\u001b[39;00m Aclosing(\u001b[38;5;28mself\u001b[39m._run_async_impl(ctx)) \u001b[38;5;28;01mas\u001b[39;00m agen:\n\u001b[32m--> \u001b[39m\u001b[32m294\u001b[39m   \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m event \u001b[38;5;129;01min\u001b[39;00m agen:\n\u001b[32m    295\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m event\n\u001b[32m    297\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m ctx.end_invocation:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Development/Google-ai/aiEnv/lib/python3.13/site-packages/google/adk/agents/llm_agent.py:435\u001b[39m, in \u001b[36mLlmAgent._run_async_impl\u001b[39m\u001b[34m(self, ctx)\u001b[39m\n\u001b[32m    433\u001b[39m should_pause = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m    434\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mwith\u001b[39;00m Aclosing(\u001b[38;5;28mself\u001b[39m._llm_flow.run_async(ctx)) \u001b[38;5;28;01mas\u001b[39;00m agen:\n\u001b[32m--> \u001b[39m\u001b[32m435\u001b[39m   \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m event \u001b[38;5;129;01min\u001b[39;00m agen:\n\u001b[32m    436\u001b[39m     \u001b[38;5;28mself\u001b[39m.__maybe_save_output_to_state(event)\n\u001b[32m    437\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m event\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Development/Google-ai/aiEnv/lib/python3.13/site-packages/google/adk/flows/llm_flows/base_llm_flow.py:356\u001b[39m, in \u001b[36mBaseLlmFlow.run_async\u001b[39m\u001b[34m(self, invocation_context)\u001b[39m\n\u001b[32m    354\u001b[39m last_event = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    355\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mwith\u001b[39;00m Aclosing(\u001b[38;5;28mself\u001b[39m._run_one_step_async(invocation_context)) \u001b[38;5;28;01mas\u001b[39;00m agen:\n\u001b[32m--> \u001b[39m\u001b[32m356\u001b[39m   \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m event \u001b[38;5;129;01min\u001b[39;00m agen:\n\u001b[32m    357\u001b[39m     last_event = event\n\u001b[32m    358\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m event\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Development/Google-ai/aiEnv/lib/python3.13/site-packages/google/adk/flows/llm_flows/base_llm_flow.py:433\u001b[39m, in \u001b[36mBaseLlmFlow._run_one_step_async\u001b[39m\u001b[34m(self, invocation_context)\u001b[39m\n\u001b[32m    422\u001b[39m model_response_event = Event(\n\u001b[32m    423\u001b[39m     \u001b[38;5;28mid\u001b[39m=Event.new_id(),\n\u001b[32m    424\u001b[39m     invocation_id=invocation_context.invocation_id,\n\u001b[32m    425\u001b[39m     author=invocation_context.agent.name,\n\u001b[32m    426\u001b[39m     branch=invocation_context.branch,\n\u001b[32m    427\u001b[39m )\n\u001b[32m    428\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mwith\u001b[39;00m Aclosing(\n\u001b[32m    429\u001b[39m     \u001b[38;5;28mself\u001b[39m._call_llm_async(\n\u001b[32m    430\u001b[39m         invocation_context, llm_request, model_response_event\n\u001b[32m    431\u001b[39m     )\n\u001b[32m    432\u001b[39m ) \u001b[38;5;28;01mas\u001b[39;00m agen:\n\u001b[32m--> \u001b[39m\u001b[32m433\u001b[39m   \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m llm_response \u001b[38;5;129;01min\u001b[39;00m agen:\n\u001b[32m    434\u001b[39m     \u001b[38;5;66;03m# Postprocess after calling the LLM.\u001b[39;00m\n\u001b[32m    435\u001b[39m     \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mwith\u001b[39;00m Aclosing(\n\u001b[32m    436\u001b[39m         \u001b[38;5;28mself\u001b[39m._postprocess_async(\n\u001b[32m    437\u001b[39m             invocation_context,\n\u001b[32m   (...)\u001b[39m\u001b[32m    441\u001b[39m         )\n\u001b[32m    442\u001b[39m     ) \u001b[38;5;28;01mas\u001b[39;00m agen:\n\u001b[32m    443\u001b[39m       \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m event \u001b[38;5;129;01min\u001b[39;00m agen:\n\u001b[32m    444\u001b[39m         \u001b[38;5;66;03m# Update the mutable event id to avoid conflict\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Development/Google-ai/aiEnv/lib/python3.13/site-packages/google/adk/flows/llm_flows/base_llm_flow.py:804\u001b[39m, in \u001b[36mBaseLlmFlow._call_llm_async\u001b[39m\u001b[34m(self, invocation_context, llm_request, model_response_event)\u001b[39m\n\u001b[32m    801\u001b[39m           \u001b[38;5;28;01myield\u001b[39;00m llm_response\n\u001b[32m    803\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mwith\u001b[39;00m Aclosing(_call_llm_with_tracing()) \u001b[38;5;28;01mas\u001b[39;00m agen:\n\u001b[32m--> \u001b[39m\u001b[32m804\u001b[39m   \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m event \u001b[38;5;129;01min\u001b[39;00m agen:\n\u001b[32m    805\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m event\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Development/Google-ai/aiEnv/lib/python3.13/site-packages/google/adk/flows/llm_flows/base_llm_flow.py:788\u001b[39m, in \u001b[36mBaseLlmFlow._call_llm_async.<locals>._call_llm_with_tracing\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    775\u001b[39m responses_generator = llm.generate_content_async(\n\u001b[32m    776\u001b[39m     llm_request,\n\u001b[32m    777\u001b[39m     stream=invocation_context.run_config.streaming_mode\n\u001b[32m    778\u001b[39m     == StreamingMode.SSE,\n\u001b[32m    779\u001b[39m )\n\u001b[32m    780\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mwith\u001b[39;00m Aclosing(\n\u001b[32m    781\u001b[39m     \u001b[38;5;28mself\u001b[39m._run_and_handle_error(\n\u001b[32m    782\u001b[39m         responses_generator,\n\u001b[32m   (...)\u001b[39m\u001b[32m    786\u001b[39m     )\n\u001b[32m    787\u001b[39m ) \u001b[38;5;28;01mas\u001b[39;00m agen:\n\u001b[32m--> \u001b[39m\u001b[32m788\u001b[39m   \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m llm_response \u001b[38;5;129;01min\u001b[39;00m agen:\n\u001b[32m    789\u001b[39m     trace_call_llm(\n\u001b[32m    790\u001b[39m         invocation_context,\n\u001b[32m    791\u001b[39m         model_response_event.id,\n\u001b[32m    792\u001b[39m         llm_request,\n\u001b[32m    793\u001b[39m         llm_response,\n\u001b[32m    794\u001b[39m     )\n\u001b[32m    795\u001b[39m     \u001b[38;5;66;03m# Runs after_model_callback if it exists.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Development/Google-ai/aiEnv/lib/python3.13/site-packages/google/adk/flows/llm_flows/base_llm_flow.py:998\u001b[39m, in \u001b[36mBaseLlmFlow._run_and_handle_error\u001b[39m\u001b[34m(self, response_generator, invocation_context, llm_request, model_response_event)\u001b[39m\n\u001b[32m    996\u001b[39m   \u001b[38;5;28;01myield\u001b[39;00m error_response\n\u001b[32m    997\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m998\u001b[39m   \u001b[38;5;28;01mraise\u001b[39;00m model_error\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Development/Google-ai/aiEnv/lib/python3.13/site-packages/google/adk/flows/llm_flows/base_llm_flow.py:982\u001b[39m, in \u001b[36mBaseLlmFlow._run_and_handle_error\u001b[39m\u001b[34m(self, response_generator, invocation_context, llm_request, model_response_event)\u001b[39m\n\u001b[32m    980\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    981\u001b[39m   \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mwith\u001b[39;00m Aclosing(response_generator) \u001b[38;5;28;01mas\u001b[39;00m agen:\n\u001b[32m--> \u001b[39m\u001b[32m982\u001b[39m     \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m response \u001b[38;5;129;01min\u001b[39;00m agen:\n\u001b[32m    983\u001b[39m       \u001b[38;5;28;01myield\u001b[39;00m response\n\u001b[32m    984\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m model_error:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Development/Google-ai/aiEnv/lib/python3.13/site-packages/google/adk/models/google_llm.py:113\u001b[39m, in \u001b[36mGemini.generate_content_async\u001b[39m\u001b[34m(self, llm_request, stream)\u001b[39m\n\u001b[32m    101\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mgenerate_content_async\u001b[39m(\n\u001b[32m    102\u001b[39m     \u001b[38;5;28mself\u001b[39m, llm_request: LlmRequest, stream: \u001b[38;5;28mbool\u001b[39m = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m    103\u001b[39m ) -> AsyncGenerator[LlmResponse, \u001b[38;5;28;01mNone\u001b[39;00m]:\n\u001b[32m    104\u001b[39m \u001b[38;5;250m  \u001b[39m\u001b[33;03m\"\"\"Sends a request to the Gemini model.\u001b[39;00m\n\u001b[32m    105\u001b[39m \n\u001b[32m    106\u001b[39m \u001b[33;03m  Args:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    111\u001b[39m \u001b[33;03m    LlmResponse: The model response.\u001b[39;00m\n\u001b[32m    112\u001b[39m \u001b[33;03m  \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m113\u001b[39m   \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._preprocess_request(llm_request)\n\u001b[32m    114\u001b[39m   \u001b[38;5;28mself\u001b[39m._maybe_append_user_content(llm_request)\n\u001b[32m    116\u001b[39m   \u001b[38;5;66;03m# Handle context caching if configured\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Development/Google-ai/aiEnv/lib/python3.13/site-packages/google/adk/models/google_llm.py:307\u001b[39m, in \u001b[36mGemini._preprocess_request\u001b[39m\u001b[34m(self, llm_request)\u001b[39m\n\u001b[32m    305\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_preprocess_request\u001b[39m(\u001b[38;5;28mself\u001b[39m, llm_request: LlmRequest) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m307\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_api_backend\u001b[49m == GoogleLLMVariant.GEMINI_API:\n\u001b[32m    308\u001b[39m     \u001b[38;5;66;03m# Using API key from Google AI Studio to call model doesn't support labels.\u001b[39;00m\n\u001b[32m    309\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m llm_request.config:\n\u001b[32m    310\u001b[39m       llm_request.config.labels = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Cellar/python@3.13/3.13.9/Frameworks/Python.framework/Versions/3.13/lib/python3.13/functools.py:1026\u001b[39m, in \u001b[36mcached_property.__get__\u001b[39m\u001b[34m(self, instance, owner)\u001b[39m\n\u001b[32m   1024\u001b[39m val = cache.get(\u001b[38;5;28mself\u001b[39m.attrname, _NOT_FOUND)\n\u001b[32m   1025\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m val \u001b[38;5;129;01mis\u001b[39;00m _NOT_FOUND:\n\u001b[32m-> \u001b[39m\u001b[32m1026\u001b[39m     val = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43minstance\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1027\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1028\u001b[39m         cache[\u001b[38;5;28mself\u001b[39m.attrname] = val\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Development/Google-ai/aiEnv/lib/python3.13/site-packages/google/adk/models/google_llm.py:214\u001b[39m, in \u001b[36mGemini._api_backend\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    210\u001b[39m \u001b[38;5;129m@cached_property\u001b[39m\n\u001b[32m    211\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_api_backend\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> GoogleLLMVariant:\n\u001b[32m    212\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[32m    213\u001b[39m       GoogleLLMVariant.VERTEX_AI\n\u001b[32m--> \u001b[39m\u001b[32m214\u001b[39m       \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mapi_client\u001b[49m.vertexai\n\u001b[32m    215\u001b[39m       \u001b[38;5;28;01melse\u001b[39;00m GoogleLLMVariant.GEMINI_API\n\u001b[32m    216\u001b[39m   )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Cellar/python@3.13/3.13.9/Frameworks/Python.framework/Versions/3.13/lib/python3.13/functools.py:1026\u001b[39m, in \u001b[36mcached_property.__get__\u001b[39m\u001b[34m(self, instance, owner)\u001b[39m\n\u001b[32m   1024\u001b[39m val = cache.get(\u001b[38;5;28mself\u001b[39m.attrname, _NOT_FOUND)\n\u001b[32m   1025\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m val \u001b[38;5;129;01mis\u001b[39;00m _NOT_FOUND:\n\u001b[32m-> \u001b[39m\u001b[32m1026\u001b[39m     val = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43minstance\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1027\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1028\u001b[39m         cache[\u001b[38;5;28mself\u001b[39m.attrname] = val\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Development/Google-ai/aiEnv/lib/python3.13/site-packages/google/adk/models/google_llm.py:203\u001b[39m, in \u001b[36mGemini.api_client\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    196\u001b[39m \u001b[38;5;129m@cached_property\u001b[39m\n\u001b[32m    197\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mapi_client\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> Client:\n\u001b[32m    198\u001b[39m \u001b[38;5;250m  \u001b[39m\u001b[33;03m\"\"\"Provides the api client.\u001b[39;00m\n\u001b[32m    199\u001b[39m \n\u001b[32m    200\u001b[39m \u001b[33;03m  Returns:\u001b[39;00m\n\u001b[32m    201\u001b[39m \u001b[33;03m    The api client.\u001b[39;00m\n\u001b[32m    202\u001b[39m \u001b[33;03m  \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m203\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mClient\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    204\u001b[39m \u001b[43m      \u001b[49m\u001b[43mhttp_options\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtypes\u001b[49m\u001b[43m.\u001b[49m\u001b[43mHttpOptions\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    205\u001b[39m \u001b[43m          \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_tracking_headers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    206\u001b[39m \u001b[43m          \u001b[49m\u001b[43mretry_options\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mretry_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    207\u001b[39m \u001b[43m      \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    208\u001b[39m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Development/Google-ai/aiEnv/lib/python3.13/site-packages/google/genai/client.py:271\u001b[39m, in \u001b[36mClient.__init__\u001b[39m\u001b[34m(self, vertexai, api_key, credentials, project, location, debug_config, http_options)\u001b[39m\n\u001b[32m    268\u001b[39m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    269\u001b[39m     http_options = HttpOptions(base_url=base_url)\n\u001b[32m--> \u001b[39m\u001b[32m271\u001b[39m \u001b[38;5;28mself\u001b[39m._api_client = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_api_client\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    272\u001b[39m \u001b[43m    \u001b[49m\u001b[43mvertexai\u001b[49m\u001b[43m=\u001b[49m\u001b[43mvertexai\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    273\u001b[39m \u001b[43m    \u001b[49m\u001b[43mapi_key\u001b[49m\u001b[43m=\u001b[49m\u001b[43mapi_key\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    274\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcredentials\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcredentials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    275\u001b[39m \u001b[43m    \u001b[49m\u001b[43mproject\u001b[49m\u001b[43m=\u001b[49m\u001b[43mproject\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    276\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlocation\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlocation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    277\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdebug_config\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_debug_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    278\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhttp_options\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhttp_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    279\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    281\u001b[39m \u001b[38;5;28mself\u001b[39m._aio = AsyncClient(\u001b[38;5;28mself\u001b[39m._api_client)\n\u001b[32m    282\u001b[39m \u001b[38;5;28mself\u001b[39m._models = Models(\u001b[38;5;28mself\u001b[39m._api_client)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Development/Google-ai/aiEnv/lib/python3.13/site-packages/google/genai/client.py:318\u001b[39m, in \u001b[36mClient._get_api_client\u001b[39m\u001b[34m(vertexai, api_key, credentials, project, location, debug_config, http_options)\u001b[39m\n\u001b[32m    301\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m debug_config \u001b[38;5;129;01mand\u001b[39;00m debug_config.client_mode \u001b[38;5;129;01min\u001b[39;00m [\n\u001b[32m    302\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mrecord\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m    303\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mreplay\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m    304\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mauto\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m    305\u001b[39m ]:\n\u001b[32m    306\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m ReplayApiClient(\n\u001b[32m    307\u001b[39m       mode=debug_config.client_mode,  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[32m    308\u001b[39m       replay_id=debug_config.replay_id,  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    315\u001b[39m       http_options=http_options,\n\u001b[32m    316\u001b[39m   )\n\u001b[32m--> \u001b[39m\u001b[32m318\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mBaseApiClient\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    319\u001b[39m \u001b[43m    \u001b[49m\u001b[43mvertexai\u001b[49m\u001b[43m=\u001b[49m\u001b[43mvertexai\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    320\u001b[39m \u001b[43m    \u001b[49m\u001b[43mapi_key\u001b[49m\u001b[43m=\u001b[49m\u001b[43mapi_key\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    321\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcredentials\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcredentials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    322\u001b[39m \u001b[43m    \u001b[49m\u001b[43mproject\u001b[49m\u001b[43m=\u001b[49m\u001b[43mproject\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    323\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlocation\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlocation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    324\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhttp_options\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhttp_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    325\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Development/Google-ai/aiEnv/lib/python3.13/site-packages/google/genai/_api_client.py:675\u001b[39m, in \u001b[36mBaseApiClient.__init__\u001b[39m\u001b[34m(self, vertexai, api_key, credentials, project, location, http_options)\u001b[39m\n\u001b[32m    673\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:  \u001b[38;5;66;03m# Implicit initialization or missing arguments.\u001b[39;00m\n\u001b[32m    674\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m.api_key:\n\u001b[32m--> \u001b[39m\u001b[32m675\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    676\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mMissing key inputs argument! To use the Google AI API,\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m    677\u001b[39m         \u001b[33m'\u001b[39m\u001b[33m provide (`api_key`) arguments. To use the Google Cloud API,\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m    678\u001b[39m         \u001b[33m'\u001b[39m\u001b[33m provide (`vertexai`, `project` & `location`) arguments.\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m    679\u001b[39m     )\n\u001b[32m    680\u001b[39m   \u001b[38;5;28mself\u001b[39m._http_options.base_url = \u001b[33m'\u001b[39m\u001b[33mhttps://generativelanguage.googleapis.com/\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m    681\u001b[39m   \u001b[38;5;28mself\u001b[39m._http_options.api_version = \u001b[33m'\u001b[39m\u001b[33mv1beta\u001b[39m\u001b[33m'\u001b[39m\n",
      "\u001b[31mValueError\u001b[39m: Missing key inputs argument! To use the Google AI API, provide (`api_key`) arguments. To use the Google Cloud API, provide (`vertexai`, `project` & `location`) arguments."
     ]
    }
   ],
   "source": [
    "print(\"ðŸš€ Running agent with LoggingPlugin...\")\n",
    "print(\"ðŸ“Š Watch the comprehensive logging output below:\\n\")\n",
    "\n",
    "response = await runner.run_debug(\"Find recent papers on quantum computing\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gemini-adk",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
